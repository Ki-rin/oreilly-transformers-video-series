{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "265db32f",
   "metadata": {},
   "source": [
    "## 14.3 Semantic searching with OpenAI Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d93f79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspired from \n",
    "#  https://github.com/openai/openai-cookbook/blob/502429c7c85fe78e0bc481e02d0ca44e2b9ad2c1/examples/Obtain_dataset.ipynb\n",
    "#  https://github.com/openai/openai-cookbook/blob/main/examples/Semantic_text_search_using_embeddings.ipynb\n",
    "\n",
    "import openai\n",
    "from openai.embeddings_utils import get_embedding\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "import numpy as np\n",
    "from sentence_transformers import util\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89f2aca4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.09814409166574478,\n",
       " 'start': 545,\n",
       " 'end': 591,\n",
       " 'answer': 'data scientist, start-up founder, and educator'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PERSON = 'Sinan Ozdemir'\n",
    "\n",
    "# Note this is NOT an efficient way to search on google. This is done simply for education purposes\n",
    "google_html = BeautifulSoup(requests.get(f'https://www.google.com/search?q={PERSON}').text).get_text()[:1024]\n",
    "\n",
    "nlp = pipeline('question-answering', \n",
    "               model='deepset/roberta-base-squad2', \n",
    "               tokenizer='deepset/roberta-base-squad2', \n",
    "               max_length=10)\n",
    "\n",
    "nlp(f'Who is {PERSON}?', google_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04e779f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 79 documents/paragraphs\n"
     ]
    }
   ],
   "source": [
    "# Our good old textbook about insects\n",
    "text = urlopen('https://www.gutenberg.org/cache/epub/10834/pg10834.txt').read().decode()\n",
    "\n",
    "# Only keep documents of at least 100 characters, same as before\n",
    "documents = list(filter(lambda x: len(x) > 100, text.split('\\r\\n\\r\\n')))\n",
    "\n",
    "print(f'There are {len(documents)} documents/paragraphs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6656209",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86d2e033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Engine engine id=text-embedding-ada-002 at 0x280ac10d0> JSON: {\n",
       "   \"created\": null,\n",
       "   \"id\": \"text-embedding-ada-002\",\n",
       "   \"object\": \"engine\",\n",
       "   \"owner\": \"openai-internal\",\n",
       "   \"permissions\": null,\n",
       "   \"ready\": true\n",
       " }]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define the engine we will use for embeddings\n",
    "ENGINE = 'text-embedding-ada-002'\n",
    "\n",
    "# list embedding engines\n",
    "[e for e in openai.Engine.list().data if 'embed' in e.id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28bc736d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure you have your API key set in your environment per the README: \n",
    "#  https://github.com/openai/openai-python#usage\n",
    "\n",
    "# This could take time if you have hundreds or thousands of documents\n",
    "embeddings = [get_embedding(document, engine=ENGINE) for document in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19c7a87b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79, 1536)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform list of lists to numpy\n",
    "document_embeddings = np.array(embeddings)\n",
    "\n",
    "document_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de7b4dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This next part will look pretty familiar\n",
    "QUESTION = 'How many horns does a flea have?'  # a natural language query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c98cfce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec83525f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'corpus_id': 14, 'score': 0.8606351385894533},\n",
       " {'corpus_id': 16, 'score': 0.8235643926092285},\n",
       " {'corpus_id': 18, 'score': 0.7948247130014698}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode the query using OpenAI and find relevant documents\n",
    "question_embedding = np.array(get_embedding(QUESTION, engine=ENGINE))\n",
    "\n",
    "# Sentence Transformers semantic search is ready to go. We could rewrite it otherwise\n",
    "hits = util.semantic_search(question_embedding, document_embeddings, top_k=3)[0]\n",
    "\n",
    "hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ada5d037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many horns does a flea have?\n",
      "\n",
      "Document 1 Cos_Sim 0.861:\n",
      "\n",
      "When examined by a microscope, the flea is a pleasant object. The body\r\n",
      "is curiously adorned with a suit of polished armour, neatly jointed, and\r\n",
      "beset with a great number of sharp pins almost like the quills of a\r\n",
      "porcupine: it has a small head, large eyes, two horns, or feelers, which\r\n",
      "proceed from the head, and four long legs from the breast; they are very\r\n",
      "hairy and long, and have several joints, which fold as it were one\r\n",
      "within another.\n",
      "\n",
      "\n",
      "Document 2 Cos_Sim 0.824:\n",
      "\n",
      "In examining the louse with a microscope, its external deformity strikes\r\n",
      "us with disgust. It has six feet, two eyes, and a sort of sting,\r\n",
      "proboscis, or sucker, with which it pierces the skin, and sucks the\r\n",
      "blood. The skin of the louse is hard and transparent, with here and\r\n",
      "there several bristly hairs: at the end of each leg are two claws, by\r\n",
      "which it is enabled to lay hold of the hairs, on which it climbs. There\r\n",
      "is scarcely any animal known to multiply so fast as this unwelcome\r\n",
      "intruder: from an experiment of Lieuenhoek, a louse in eight weeks, may\r\n",
      "see five thousand of its descendants.\n",
      "\n",
      "\n",
      "Document 3 Cos_Sim 0.795:\n",
      "\n",
      "\r\n",
      "There are many species of mites, beside the itch animal and mite above:\r\n",
      "to the naked eye, they appear like moving particles of dust: but the\r\n",
      "microscope discovers them to be perfect animals, having as regular a\r\n",
      "figure, and performing all the functions of life as perfectly as\r\n",
      "creatures that exceed them many times in bulk: their eggs are so small\r\n",
      "that a regular computation shews that 90 millions of them are not so\r\n",
      "large as a common Pigeon's egg.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'Question: {QUESTION}\\n')\n",
    "\n",
    "for i, hit in enumerate(hits):\n",
    "    \n",
    "    print(f'Document {i + 1} Cos_Sim {hit[\"score\"]:.3f}:\\n\\n{documents[hit[\"corpus_id\"]]}')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e32cdde7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.8524730801582336, 'start': 259, 'end': 262, 'answer': 'two'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# answer the question from the top document\n",
    "nlp(QUESTION, str(documents[hits[0]['corpus_id']]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f7fbca",
   "metadata": {},
   "source": [
    "# Let's use GPT3 to answer instead\n",
    "![](../data/gptqa.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "33309e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = documents[hits[0]['corpus_id']]\n",
    "\n",
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-003\",\n",
    "  prompt=f\"Given this context, answer the question.\\n\\nContext: {context}\\nQuery: {QUESTION}\\nAnswer:\",\n",
    "  temperature=0.7,\n",
    "  max_tokens=25,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4cfa74fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-6XBeNcL9GBIvqlExVG2dztFBMFIrZ at 0x28288a930> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \" A flea has two horns.\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1673367627,\n",
       "  \"id\": \"cmpl-6XBeNcL9GBIvqlExVG2dztFBMFIrZ\",\n",
       "  \"model\": \"text-davinci-003\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 7,\n",
       "    \"prompt_tokens\": 143,\n",
       "    \"total_tokens\": 150\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "59e31b9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' A flea has two horns.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the completion\n",
    "response['choices'][0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "940e0764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some more fun asking GPT to respond to a 2nd grader\n",
    "\n",
    "context = documents[hits[0]['corpus_id']]\n",
    "\n",
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-003\",\n",
    "  prompt=f\"Given this context, answer the question so a second grader can understand.\\n\\nContext: {context}\\nQuery: {QUESTION}\\nAnswer:\",\n",
    "  temperature=0.7,\n",
    "  max_tokens=25,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3f7bb1c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' A flea has two horns, which look like feelers coming out of its head.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the completion, with some more flavor\n",
    "response['choices'][0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b92ae45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc636851",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
